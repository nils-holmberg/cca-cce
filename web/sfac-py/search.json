[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Python",
    "section": "",
    "text": "Figure 1: Official logo of the Python programming language\n\n\nAnother principle that has guided the design of this course is that participants should gain an understanding of how Python can be used to accomplish fairly common research tasks within the social sciences more effectively and more transparently. Such applications of Python include collecting and analyzing survey data, performing content analyses on textual and visual material, and using charts to visualize results.\n\nThis is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "inst-221017-tables.html",
    "href": "inst-221017-tables.html",
    "title": "day 1: data tables analysis",
    "section": "",
    "text": "Reference to this dataset is Horst et al. (2020)."
  },
  {
    "objectID": "inst-221017-tables.html#jupyter-notebooks",
    "href": "inst-221017-tables.html#jupyter-notebooks",
    "title": "day 1: data tables analysis",
    "section": "1 jupyter notebooks",
    "text": "1 jupyter notebooks\nOn the first workshop session day 1 we will ensure that everyone can get access to a working extensible python environment. The Anaconda3 python environment consists of three main tools: 1) Anaconda navigator for handling environments and packages, 2) Spyder for writing python scripts, and 3) Jupyter notebook for executing interactive code blocks. If you dont have access to Anaconda3 on a local computer, you should be able to follow along from section 1.2.1 below using the google colab cloud service instead.\n\n\n\n\nTable 1: workshop section 1.1.1\n\n\n\n\n\n\n\n\ntime\nsection\nconcepts\noutcomes\n\n\n\n\n13-14\n1.1.1\nanaconda3\nunderstand install location, create and update virtual environments\n\n\n\n1.1.2\njupyter\ndownload course material, open notebooks, edit in web browser\n\n\n\n1.1.3\ntesting\nexecute the hello world example in jupyter python env\n\n\n\nbreak"
  },
  {
    "objectID": "inst-221017-tables.html#basic-syntax",
    "href": "inst-221017-tables.html#basic-syntax",
    "title": "day 1: data tables analysis",
    "section": "2 basic syntax",
    "text": "2 basic syntax\nDownload the following notebook file and save it to a location where you can find it (121.ipynb). Start your Anaconda navigator app and launch Jupyter notebook from your base environment. Navigate to the notebook file and open it in Jupyter notebook that is running in your web browser. Start executing the notebook code blocks by clicking the play button or by pressing the shift + enter keys. Try editing the code cells and observe the output changes.\n\n\n\n\nTable 2: workshop section 1.2.1\n\n\n\n\n\n\n\n\ntime\nsection\nconcepts\noutcomes\n\n\n\n\n14-15\n1.2.1\npython syntax\npractice data structures, conditional statements, flow control\n\n\n\n1.2.2\nfunctions\nreusable pieces of code, understand relation to modules\n\n\n\n1.2.3\nfiles, directories\nnavigate the file system, read, write data files\n\n\n\nbreak\n\n\n\n\n\n\n\n\nYou have now started exploring the basic syntax of the python programming language. Continue by trying out some data objects such as list and dictionaries, and some flow control structures using the if, for, and while statements. Next, you can download the notebook for testing functions (122.ipynb). Open the new file using Jupyter in your web browser and try some example of functions. In the same notebook file you will also find some examples of how to read and write data files using python."
  },
  {
    "objectID": "inst-221017-tables.html#structured-data",
    "href": "inst-221017-tables.html#structured-data",
    "title": "day 1: data tables analysis",
    "section": "3 structured data",
    "text": "3 structured data\nLearning the syntax of python takes a lot of practice. In order to proceed more quickly, we will henceforth employ a “low-code” approach to python in which we focus on manipulating larger code blocks. This will become useful when working with tablular data using the python pandas package, which is the final outcome of day 1 of this workshop. Let’s start by downloading a new notebook file (131.ipynb) and opening it in Jupyter.\n\n\n\n\nTable 3: workshop section 1.3.1\n\n\n\n\n\n\n\n\ntime\nsection\nconcepts\noutcomes\n\n\n\n\n15-16\n1.3.1\ntabular data\nunderstand how to read, write, and process survey data\n\n\n\n1.3.2\nsummarize\naggregate, combine, join operations\n\n\n\n1.3.3\nsubset, substitute\nand reshape, maybe try out ggplot-like package siuba\n\n\n16-17\nbreak\nanaconda, continued\ntry to resolve anaconda, psychopy installation problems\n\n\n\n\n\n\nAfter we haved practiced reading some table data into python, we will focus on data wrangling and how to use python pandas to perform various types of descriptive summarizations of the data (132.ipynb). By working with the penguins dataset introduced earlier, we will then prepare our data to get a suitable format for data visualizations (133.ipynb)."
  },
  {
    "objectID": "inst-221017-tables.html#data-visualization",
    "href": "inst-221017-tables.html#data-visualization",
    "title": "day 1: data tables analysis",
    "section": "4 data visualization",
    "text": "4 data visualization\nHere is a sneak preview of day 2 of the workshop. For a demonstration of a line plot on a polar axis, see Figure 2.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\nFigure 2: A line plot on a polar axis"
  },
  {
    "objectID": "topics-3-cca-cv.html#headline-2",
    "href": "topics-3-cca-cv.html#headline-2",
    "title": "computer vision (cv)",
    "section": "2 headline 2",
    "text": "2 headline 2"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "resources",
    "section": "",
    "text": "Neuendorf (2017)\n\n\n\n\n\n\n\nKedia & Rasu (2020)\n\n\n\n\n\n\n\nSzeliski (2010)"
  },
  {
    "objectID": "resources.html#websites-and-apps",
    "href": "resources.html#websites-and-apps",
    "title": "resources",
    "section": "websites and apps",
    "text": "websites and apps\n\nhttps://www.python.org/downloads/\nhttps://wiki.python.org/moin/BeginnersGuide\nhttps://www.anaconda.com/products/individual\nhttps://code.visualstudio.com/download\nhttps://github.com/jupyterlab/jupyterlab_app#download\nhttps://trinket.io/home"
  },
  {
    "objectID": "resources.html#online-articles",
    "href": "resources.html#online-articles",
    "title": "resources",
    "section": "online articles",
    "text": "online articles\n\nsome text here Kedia & Rasu (2020)"
  },
  {
    "objectID": "topics-1-tab-vis.html",
    "href": "topics-1-tab-vis.html",
    "title": "data analysis and visualizations",
    "section": "",
    "text": "Using pandas package to process table data."
  },
  {
    "objectID": "topics-1-tab-vis.html#data-visualizations",
    "href": "topics-1-tab-vis.html#data-visualizations",
    "title": "data analysis and visualizations",
    "section": "2 data visualizations",
    "text": "2 data visualizations\nUsing packages to visualize data."
  },
  {
    "objectID": "topics-2-cca-nlp.html#headline-2",
    "href": "topics-2-cca-nlp.html#headline-2",
    "title": "natural language processing (nlp)",
    "section": "2 headline 2",
    "text": "2 headline 2"
  },
  {
    "objectID": "inst-221020-nlp-tc.html#topic-modelling",
    "href": "inst-221020-nlp-tc.html#topic-modelling",
    "title": "day 4: text classification",
    "section": "1 topic modelling",
    "text": "1 topic modelling\n\n411.ipynb\n412.ipynb\n413.ipynb\n\n\n\n\n\nTable 1: workshop section 4.1\n\n\n\n\n\n\n\n\ntime\nsection\nconcepts\noutcomes\n\n\n\n\n13-14\n4.1.1\ntf-idf analysis\ndata structures, text frequency, inverse document frequecy\n\n\n\n4.1.2\npython syntax\npractice data structures, conditional statements, flow control\n\n\n\n4.1.3\ntopic modelling\ndocument clusters, applying unsupervised learning to texts\n\n\n\nbreak"
  },
  {
    "objectID": "inst-221020-nlp-tc.html#word-vectors",
    "href": "inst-221020-nlp-tc.html#word-vectors",
    "title": "day 4: text classification",
    "section": "2 word vectors",
    "text": "2 word vectors\n\n421.ipynb\n422.ipynb\n423.ipynb\n\n\n\n\n\nTable 2: workshop section 4.2\n\n\n\n\n\n\n\n\ntime\nsection\nconcepts\noutcomes\n\n\n\n\n14-15\n4.2.1\nnamed entities\ntext named entity recognition (ner) using spacy\n\n\n\n4.2.2\ntext similarity\n\n\n\n\n4.2.3\nword vectors\ntime series\n\n\n\nbreak"
  },
  {
    "objectID": "inst-221020-nlp-tc.html#text-classification",
    "href": "inst-221020-nlp-tc.html#text-classification",
    "title": "day 4: text classification",
    "section": "3 text classification",
    "text": "3 text classification\n\n\n\n\nTable 3: workshop section 4.3\n\n\n\n\n\n\n\n\ntime\nsection\nconcepts\noutcomes\n\n\n\n\n15-16\n4.3.1\ntext classification\ntext classification using deep learning, neural networks\n\n\n\n4.3.2\nsentiment analysis\nbinary text classification\n\n\n\n4.3.3\ntopic classes\nmulti-class text classification\n\n\n16-17\nbreak\n\n\n\n\n\n\n\n\n\n431.ipynb\n432.ipynb\n433.ipynb"
  },
  {
    "objectID": "inst-221020-nlp-tc.html#some-headline",
    "href": "inst-221020-nlp-tc.html#some-headline",
    "title": "day 4: text classification",
    "section": "4 some headline",
    "text": "4 some headline"
  },
  {
    "objectID": "instructions.html",
    "href": "instructions.html",
    "title": "workshop instructions",
    "section": "",
    "text": "Course participants are encouraged to install a Python environment beforehand. The environment used on this course will be Anaconda3 and it consists of several modules, including support for interacting with Jupyter notebooks, which will be the main format of instruction on the course. If you plan to use a managed laptop from Lund University, please check with IT support how to install Anaconda3 via Software Center.1"
  },
  {
    "objectID": "instructions.html#jupyter-notebooks",
    "href": "instructions.html#jupyter-notebooks",
    "title": "workshop instructions",
    "section": "2 jupyter notebooks",
    "text": "2 jupyter notebooks"
  },
  {
    "objectID": "instructions.html#workshop-instructor",
    "href": "instructions.html#workshop-instructor",
    "title": "workshop instructions",
    "section": "3 workshop instructor",
    "text": "3 workshop instructor\n\n\n\nFigure 1: workshop instructor\n\n\nhttps://portal.research.lu.se/en/persons/nils-holmberg"
  },
  {
    "objectID": "schedule.html#course-overview",
    "href": "schedule.html#course-overview",
    "title": "workshop schedule",
    "section": "course overview",
    "text": "course overview\nPython is a programming language that has gained popularity in all types of data science.\n\n\n\n\nTable 1: Some nice table caption.\n\n\n\n\n\n\n\nCourse date\nCourse topic\nPython packages\n\n\n\n\n2022-10-17\nthe anaconda3 environment, basic python syntax, process table data\njupyter, scipy, pandas\n\n\n2022-10-18\ndata visualization, reproducible data analysis, sharing and collaborating\nseaborn, altair, plotly\n\n\n2022-10-19\ntext analysis, manifest content, data cleaning, tokenization, copora\nnltk, pandas, plotly\n\n\n2022-10-20\ntext analysis, latent content features, sentiment analysis, topic modelling\nscikit-learn, spacy\n\n\n2022-10-21\nimage analysis, latent content features, object recognition, captioning\nopencv, pytorch, tf"
  },
  {
    "objectID": "schedule.html#day-1-221017",
    "href": "schedule.html#day-1-221017",
    "title": "workshop schedule",
    "section": "day 1, 221017",
    "text": "day 1, 221017\nWe will set up a python evironment with support for Jupyter notebooks, and we will get an introduction to working with tabluar data.\n\n\n\n\nTable 2: Some nice table caption.\n\n\n\n\n\n\n\n\ntime\nsection\nconcepts\noutcomes\n\n\n\n\n13-14\n1.1.1\nanaconda3\nunderstand install location, create and update virtual environments\n\n\n\n1.1.2\njupyter\ndownload course material, open notebooks, edit in web browser\n\n\n\n1.1.3\ntesting\nexecute the hello world example in jupyter python env\n\n\n\nbreak\n\n\n\n\n14-15\n1.2.1\npython syntax\npractice data structures, conditional statements, flow control\n\n\n\n1.2.2\nfunctions\nreusable pieces of code, understand relation to modules\n\n\n\n1.2.3\nfiles, directories\nnavigate the file system, read, write data files\n\n\n\nbreak\n\n\n\n\n15-16\n1.3.1\ntabular data\nunderstand how to read, write, and process survey data\n\n\n\n1.3.2\nsummarize\naggregate, combine, join operations\n\n\n\n1.3.3\nsubset, substitute\nand reshape, maybe try out ggplot-like package siuba\n\n\n16-17\nbreak\nanaconda, continued\ntry to resolve anaconda, psychopy installation problems"
  },
  {
    "objectID": "schedule.html#day-2-221018",
    "href": "schedule.html#day-2-221018",
    "title": "workshop schedule",
    "section": "day 2, 221018",
    "text": "day 2, 221018\nWe will continue to work with tabular data and explore how these data can be visualized through plotting graphs.\n\n\n\n\nTable 3: Some nice table caption.\n\n\n\n\n\n\n\n\ntime\nsection\nconcepts\noutcomes\n\n\n\n\n13-14\n2.1.1\ngraphics\nunderstand python for data visualization, matplotlib\n\n\n\n2.1.2\npython syntax\npractice data structures, conditional statements, flow control\n\n\n\n2.1.3\nmodel plot\nplot linear regression model using matplotlib\n\n\n\nbreak\n\n\n\n\n14-15\n2.2.1\nplotting\nbasic static plots with matplotlib and seaborn\n\n\n\n2.2.2\nbar charts\n\n\n\n\n2.2.3\nscatter plots\ntime series\n\n\n\nbreak\n\n\n\n\n15-16\n2.3.1\nsome\ncomputational documents using altair\n\n\n\n2.3.2\ninteractive\ncreating interactive dashboards with plotly and dash\n\n\n\n2.3.3\ntopic\nand reshape, maybe try out ggplot-like package plotnine\n\n\n16-17\nbreak"
  },
  {
    "objectID": "schedule.html#day-3-221019",
    "href": "schedule.html#day-3-221019",
    "title": "workshop schedule",
    "section": "day 3, 221019",
    "text": "day 3, 221019\nWe will get an introduction to working with unstructured text data in python. Text data will be read into python and cleaned for further analyses.\n\n\n\n\nTable 4: Some nice table caption.\n\n\n\n\n\n\n\n\ntime\nsection\nconcepts\noutcomes\n\n\n\n\n13-14\n3.1.1\ncreate, read text\npython support for representing texts as data objects\n\n\n\n3.1.2\npython syntax\npractice data structures, conditional statements, flow control\n\n\n\n3.1.3\nnltk, spacy\nunderstand python for nlp, natural language toolkit, spacy\n\n\n\nbreak\n\n\n\n\n14-15\n3.2.1\ntokenization\ntext data cleaning, analyzing sentences and words\n\n\n\n3.2.2\nnormalization\nlexicon normalization, stemming and lemmatization\n\n\n\n3.2.3\npart of speech\nsyntactic function of text\n\n\n\nbreak\n\n\n\n\n15-16\n3.3.1\ntext corpus\nmanage large collections of text documents\n\n\n\n3.3.2\nbag of words\nmore on text transformation to useful data structures\n\n\n\n3.3.3\ndoc term matrix\ntransformation of texts into useful data structures\n\n\n16-17\nbreak"
  },
  {
    "objectID": "schedule.html#day-4-221020",
    "href": "schedule.html#day-4-221020",
    "title": "workshop schedule",
    "section": "day 4, 221020",
    "text": "day 4, 221020\nPython is a programming language that has gained popularity in all types of data science.\n\n\n\n\nTable 5: Some nice table caption.\n\n\n\n\n\n\n\n\ntime\nsection\nconcepts\noutcomes\n\n\n\n\n13-14\n4.1.1\ntf-idf analysis\ndata structures, text frequency, inverse document frequecy\n\n\n\n4.1.2\npython syntax\npractice data structures, conditional statements, flow control\n\n\n\n4.1.3\ntopic modelling\ndocument clusters, applying unsupervised learning to texts\n\n\n\nbreak\n\n\n\n\n14-15\n4.2.1\nnamed entities\ntext named entity recognition (ner) using spacy\n\n\n\n4.2.2\ntext similarity\n\n\n\n\n4.2.3\nword vectors\ntime series\n\n\n\nbreak\n\n\n\n\n15-16\n4.3.1\ntext classification\ntext classification using deep learning, neural networks\n\n\n\n4.3.2\nsentiment analysis\nbinary text classification\n\n\n\n4.3.3\ntopic classes\nmulti-class text classification\n\n\n16-17\nbreak"
  },
  {
    "objectID": "schedule.html#day-5-221021",
    "href": "schedule.html#day-5-221021",
    "title": "workshop schedule",
    "section": "day 5, 221021",
    "text": "day 5, 221021\nPython is a programming language that has gained popularity in all types of data science.\n\n\n\n\nTable 6: Some nice table caption.\n\n\n\n\n\n\n\n\ntime\nsection\nconcepts\noutcomes\n\n\n\n\n13-14\n5.1.1\ngraphics\nread images\n\n\n\n5.1.2\npython syntax\npractice data structures, conditional statements, flow control\n\n\n\n5.1.3\nrender images\nmanipulate images, testing the opencv library\n\n\n\nbreak\n\n\n\n\n14-15\n5.2.1\nimage preprocessing\nusing opencv to normalize image data\n\n\n\n5.2.2\nocr classification\ntesting deep learning using the mnist dataset (mlp)\n\n\n\n5.2.3\nimage class\nfirst convolutional neural networks (cnn)\n\n\n\nbreak\n\n\n\n\n15-16\n5.3.1\nobject recognition\nmulti-class image classification using pytorch, tensorflow\n\n\n\n5.3.2\nlocalization\nlocalize object bounding boxes, find object contours\n\n\n\n5.3.3\nimage captioning\nsummarize image content and actions as text description\n\n\n16-17\nbreak"
  },
  {
    "objectID": "inst-221021-cv-img.html",
    "href": "inst-221021-cv-img.html",
    "title": "day 5: image recognition",
    "section": "",
    "text": "This day of the workshop we will focus on python machine learning tasks in the image domain. Previously we have worked with classifying texts and words, and now we will try to perform similar tasks on image pixels. This type of content analysis can be regarded as a subset of the field of computer vision."
  },
  {
    "objectID": "inst-221021-cv-img.html#working-with-images",
    "href": "inst-221021-cv-img.html#working-with-images",
    "title": "day 5: image recognition",
    "section": "1 working with images",
    "text": "1 working with images\nImage data is highly structured compared to text. An image always contains a specific number of rows and columns (pixel dimensions), and each cell (pixel) contains three normalized values between 0 and 255 (RGB color).\n\n\n\n\nTable 1: workshop section 5.1\n\n\n\n\n\n\n\n\ntime\nsection\nconcepts\noutcomes\n\n\n\n\n13-14\n5.1.1\ngraphics\nread images\n\n\n\n5.1.2\npython syntax\npractice data structures, conditional statements, flow control\n\n\n\n5.1.3\nrender images\nmanipulate images, testing the opencv library\n\n\n\nbreak\n\n\n\n\n\n\n\n\n\n511.ipynb\n512.ipynb\n513.ipynb"
  },
  {
    "objectID": "inst-221021-cv-img.html#image-classification",
    "href": "inst-221021-cv-img.html#image-classification",
    "title": "day 5: image recognition",
    "section": "2 image classification",
    "text": "2 image classification\n\n\n\n\nTable 2: workshop section 5.2\n\n\n\n\n\n\n\n\ntime\nsection\nconcepts\noutcomes\n\n\n\n\n14-15\n5.2.1\nimage preprocessing\nusing opencv to normalize image data\n\n\n\n5.2.2\nocr classification\ntesting deep learning using the mnist dataset (mlp)\n\n\n\n5.2.3\nimage class\nfirst convolutional neural networks (cnn)\n\n\n\nbreak\n\n\n\n\n\n\n\n\n\n521.ipynb\n522.ipynb\n523.ipynb"
  },
  {
    "objectID": "inst-221021-cv-img.html#object-recognition",
    "href": "inst-221021-cv-img.html#object-recognition",
    "title": "day 5: image recognition",
    "section": "3 object recognition",
    "text": "3 object recognition\n\n\n\n\nTable 3: workshop section 5.3\n\n\n\n\n\n\n\n\ntime\nsection\nconcepts\noutcomes\n\n\n\n\n15-16\n5.3.1\nobject recognition\nmulti-class image classification using pytorch, tensorflow\n\n\n\n5.3.2\nlocalization\nlocalize object bounding boxes, find object contours\n\n\n\n5.3.3\nimage captioning\nsummarize image content and actions as text description\n\n\n16-17\nbreak\n\n\n\n\n\n\n\n\n\n531.ipynb\n532.ipynb\n533.ipynb"
  },
  {
    "objectID": "inst-221021-cv-img.html#some-headline",
    "href": "inst-221021-cv-img.html#some-headline",
    "title": "day 5: image recognition",
    "section": "4 some headline",
    "text": "4 some headline"
  },
  {
    "objectID": "inst-221019-nlp-dc.html#texts-and-nlp",
    "href": "inst-221019-nlp-dc.html#texts-and-nlp",
    "title": "day 3: text data analysis",
    "section": "1 texts and nlp",
    "text": "1 texts and nlp\nIf images (and some tables) represent highly structured data, texts can often be found in the other extreme of the spectrum, consisting of highly unstructured data. This poses some unique challenges with text analysis, and the solutions often deals with some aspect of making texts more structured. … in the first part of this session, we will simply load a collection of texts\n\n\n\n\nTable 1: workshop section 3.1\n\n\n\n\n\n\n\n\ntime\nsection\nconcepts\noutcomes\n\n\n\n\n13-14\n3.1.1\ncreate, read text\npython support for representing texts as data objects\n\n\n\n3.1.2\npython syntax\npractice data structures, conditional statements, flow control\n\n\n\n3.1.3\nnltk, spacy\nunderstand python for nlp, natural language toolkit, spacy\n\n\n\nbreak\n\n\n\n\n\n\n\n\n\n311.ipynb\n312.ipynb\n313.ipynb\n\nInstall and access NLTK and spaCy packages. Read"
  },
  {
    "objectID": "inst-221019-nlp-dc.html#structure-text",
    "href": "inst-221019-nlp-dc.html#structure-text",
    "title": "day 3: text data analysis",
    "section": "2 structure text",
    "text": "2 structure text\n\n321.ipynb\n322.ipynb\n323.ipynb\n\n\n\n\n\nTable 2: workshop section 3.2\n\n\n\n\n\n\n\n\ntime\nsection\nconcepts\noutcomes\n\n\n\n\n14-15\n3.2.1\ntokenization\ntext data cleaning, analyzing sentences and words\n\n\n\n3.2.2\nnormalization\nlexicon normalization, stemming and lemmatization\n\n\n\n3.2.3\npart of speech\nsyntactic function of text\n\n\n\nbreak"
  },
  {
    "objectID": "inst-221019-nlp-dc.html#text-collections",
    "href": "inst-221019-nlp-dc.html#text-collections",
    "title": "day 3: text data analysis",
    "section": "3 text collections",
    "text": "3 text collections\n\n331.ipynb\n332.ipynb\n333.ipynb\n\n\n\n\n\nTable 3: workshop section 3.3\n\n\n\n\n\n\n\n\ntime\nsection\nconcepts\noutcomes\n\n\n\n\n15-16\n3.3.1\ntext corpus\nmanage large collections of text documents\n\n\n\n3.3.2\nbag of words\nmore on text transformation to useful data structures\n\n\n\n3.3.3\ndoc term matrix\ntransformation of texts into useful data structures\n\n\n16-17\nbreak"
  },
  {
    "objectID": "inst-221019-nlp-dc.html#some-headline",
    "href": "inst-221019-nlp-dc.html#some-headline",
    "title": "day 3: text data analysis",
    "section": "4 some headline",
    "text": "4 some headline"
  },
  {
    "objectID": "inst-221018-visual.html",
    "href": "inst-221018-visual.html",
    "title": "day 2: data visualization",
    "section": "",
    "text": "Reference to this dataset is Horst et al. (2020)."
  },
  {
    "objectID": "inst-221018-visual.html#graphics-and-images",
    "href": "inst-221018-visual.html#graphics-and-images",
    "title": "day 2: data visualization",
    "section": "1 graphics and images",
    "text": "1 graphics and images\nThe main focus on day 2 of the workshop is data visualization. But we will start off by continuing to work with structured tabular data that typically underlie data visualizations. On the first session we will work on a notbook (211.ipynb) introducing the classical python plotting library called matplotlib (https://matplotlib.org/).\n\n211.ipynb\n212.ipynb\n213.ipynb\n\n\n\n\n\nTable 1: workshop section 2.1.1\n\n\n\n\n\n\n\n\ntime\nsection\nconcepts\noutcomes\n\n\n\n\n13-14\n2.1.1\ngraphics\nunderstand python for data visualization, matplotlib\n\n\n\n2.1.2\npython syntax\npractice data structures, conditional statements, flow control\n\n\n\n2.1.3\nmodel plot\nplot linear regression model using matplotlib\n\n\n\nbreak\n\n\n\n\n\n\n\n\nNext we will continue the daily practising on basic python syntax 212.ipynb."
  },
  {
    "objectID": "inst-221018-visual.html#basic-static-plots",
    "href": "inst-221018-visual.html#basic-static-plots",
    "title": "day 2: data visualization",
    "section": "2 basic static plots",
    "text": "2 basic static plots\nWhile the matplotlib library is very powerful it also quite low-level, and so it is not considered the most userfriendly. Enter the seaborn package! Built on top of matplotlib\n\n221.ipynb\n222.ipynb\n223.ipynb\n\n\n\n\n\nTable 2: workshop section 2.2.1\n\n\n\n\n\n\n\n\ntime\nsection\nconcepts\noutcomes\n\n\n\n\n14-15\n2.2.1\nplotting\nbasic static plots with matplotlib and seaborn\n\n\n\n2.2.2\nbar charts\n\n\n\n\n2.2.3\nscatter plots\ntime series\n\n\n\nbreak"
  },
  {
    "objectID": "inst-221018-visual.html#interactive-plots",
    "href": "inst-221018-visual.html#interactive-plots",
    "title": "day 2: data visualization",
    "section": "3 interactive plots",
    "text": "3 interactive plots\n\n231.ipynb\n232.ipynb\n233.ipynb\n\n\n\n\n\nTable 3: workshop section 2.3.1\n\n\n\n\n\n\n\n\ntime\nsection\nconcepts\noutcomes\n\n\n\n\n15-16\n2.3.1\nsome\ncomputational documents using altair\n\n\n\n2.3.2\ninteractive\ncreating interactive dashboards with plotly and dash\n\n\n\n2.3.3\ntopic\nand reshape, maybe try out ggplot-like package plotnine\n\n\n16-17\nbreak"
  },
  {
    "objectID": "inst-221018-visual.html#some-headline",
    "href": "inst-221018-visual.html#some-headline",
    "title": "day 2: data visualization",
    "section": "4 some headline",
    "text": "4 some headline\n\n# get altair graphics\nimport altair as alt\n# get data object from vega_datasets\nfrom vega_datasets import data\n\n\n# Selecting the data\ndf = data.iris()\n  \n# Making the Scatter Plot\nalt.Chart(df).mark_point().encode(\n    # Map the sepalLength to x-axis\n    x='sepalLength',\n    # Map the petalLength to y-axis\n    y='petalLength',\n    # Map the species to shape\n    shape='species',\n    #\n    color='species'\n)"
  },
  {
    "objectID": "topics.html",
    "href": "topics.html",
    "title": "workshop topics",
    "section": "",
    "text": "In this introduction to Python for social scientists you will learn how to use the Python programming language as a unified platform for handling multiple tasks and workflows connected to running research studies, collecting data, and analyzing numeric and textual data. On the schedule page we present an overview of the course topics covered each day, and further down we expand on each topic in some more detail."
  },
  {
    "objectID": "topics.html#data-analysis-and-visualizations",
    "href": "topics.html#data-analysis-and-visualizations",
    "title": "workshop topics",
    "section": "1 data analysis and visualizations",
    "text": "1 data analysis and visualizations\nwe will read, analyze and process some generic tabular datasets (McKinney, 2012; VanderPlas, 2016). Some data analysis. Reference to tidy data\n\n\n\nFigure 1: palmer penguins\n\n\nReference to this dataset is Horst et al. (2020).\nOn day 2, we will continue performing basic data summarization using descriptive statistics, but now we will put more emphasis on how to use quantitative data to produce compelling and intuitive visualizations. Using the matplotlib and seaborn packages, we will learn how to aggregate survey data and present them as scatter plots, bar charts, and time series (Embarak et al., 2018). If there is time, we will also use the scikit-learn package to perform multiple regression analyses in Python. data visualization"
  },
  {
    "objectID": "topics.html#computational-content-analysis",
    "href": "topics.html#computational-content-analysis",
    "title": "workshop topics",
    "section": "2 computational content analysis",
    "text": "2 computational content analysis\nFirst aspect of CCA is natural language processing (nlp), while the second aspect is computer vision (cv)."
  }
]