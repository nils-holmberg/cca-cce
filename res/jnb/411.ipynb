{"cells":[{"cell_type":"markdown","id":"42854afb-74d8-401d-a35a-6b57ebcdb710","metadata":{"id":"42854afb-74d8-401d-a35a-6b57ebcdb710"},"source":["### Word vectors and similarity \n","\n","To learn more about word vectors, how to **customize them** and how to load\n","**your own vectors** into spaCy, see the usage guide on\n","[using word vectors and semantic similarities](/usage/linguistic-features#vectors-similarity).\n"]},{"cell_type":"code","execution_count":null,"id":"935f88d0-5246-41d2-a25a-a77d10482cfd","metadata":{"id":"935f88d0-5246-41d2-a25a-a77d10482cfd"},"outputs":[],"source":["#from textblob import TextBlob"]},{"cell_type":"markdown","id":"13c0cb4e-8ae8-4c20-98a1-39246f4f59a8","metadata":{"id":"13c0cb4e-8ae8-4c20-98a1-39246f4f59a8"},"source":["## Word vectors and similarity"]},{"cell_type":"markdown","id":"168161dc-94b9-493e-92e9-b02e87c4d3f4","metadata":{"id":"168161dc-94b9-493e-92e9-b02e87c4d3f4"},"source":["To use vectors in spaCy, you might consider installing the larger models for the particular language. The common module and language packages only come with the small models. The larger models can be installed as described on the [spaCy vectors page](https://spacy.io/usage/vectors-similarity):\n","\n","    python -m spacy download en_core_web_lg\n","\n","The large model *en_core_web_lg* contains more than 1 million unique vectors."]},{"cell_type":"markdown","id":"3534fd3d-3595-460c-87e3-4a01ab36fd0a","metadata":{"id":"3534fd3d-3595-460c-87e3-4a01ab36fd0a"},"source":["Let us restart all necessary modules again, in particular spaCy:"]},{"cell_type":"code","execution_count":3,"id":"80abb48d-c176-4f98-89ab-27c2aac01b65","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"80abb48d-c176-4f98-89ab-27c2aac01b65","executionInfo":{"status":"ok","timestamp":1666261035571,"user_tz":-120,"elapsed":139171,"user":{"displayName":"Nils Holmberg","userId":"03719824180037236130"}},"outputId":"c80bf5bd-7db5-49cf-a9ea-2e05dc96128e"},"outputs":[{"output_type":"stream","name":"stdout","text":["2022-10-20 10:15:00.377399: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting en-core-web-lg==3.4.1\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.4.1/en_core_web_lg-3.4.1-py3-none-any.whl (587.7 MB)\n","\u001b[K     |████████████████████████████████| 587.7 MB 16 kB/s \n","\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-lg==3.4.1) (3.4.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.11.3)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (21.3)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.0.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.9.2)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.10)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.4.4)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (8.1.4)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.6.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.0.9)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.8)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.3.0)\n","Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (4.1.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.23.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.10.1)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.4.2)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.7)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.8)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (4.64.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (57.4.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (5.2.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2022.9.24)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.0.3)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.7.8)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.1)\n","Installing collected packages: en-core-web-lg\n","Successfully installed en-core-web-lg-3.4.1\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_lg')\n"]}],"source":["!python -m spacy download en_core_web_lg\n","import spacy"]},{"cell_type":"markdown","id":"55f4f516-9a62-41ee-87bc-e97afd5c98d1","metadata":{"id":"55f4f516-9a62-41ee-87bc-e97afd5c98d1"},"source":["We can now import the English NLP pipeline to process some word list. Since the small models in spacy only include context-sensitive tensors, we should use the dowloaded large model for better word vectors. We load the large model as follows:"]},{"cell_type":"code","execution_count":4,"id":"dc35f254-07f0-427f-af53-988eff474f4f","metadata":{"id":"dc35f254-07f0-427f-af53-988eff474f4f","executionInfo":{"status":"ok","timestamp":1666261043663,"user_tz":-120,"elapsed":2240,"user":{"displayName":"Nils Holmberg","userId":"03719824180037236130"}}},"outputs":[],"source":["nlp = spacy.load('en_core_web_lg')\n","#nlp = spacy.load(\"en_core_web_sm\")"]},{"cell_type":"markdown","id":"fab34cf8-42bc-43ba-9fed-47f4af3d7fe3","metadata":{"id":"fab34cf8-42bc-43ba-9fed-47f4af3d7fe3"},"source":["We can process a list of words by the pipeline using the *nlp* object:"]},{"cell_type":"code","execution_count":5,"id":"db26d415-b60b-48ef-a4c5-f719c9a705f7","metadata":{"id":"db26d415-b60b-48ef-a4c5-f719c9a705f7","executionInfo":{"status":"ok","timestamp":1666261049494,"user_tz":-120,"elapsed":416,"user":{"displayName":"Nils Holmberg","userId":"03719824180037236130"}}},"outputs":[],"source":["tokens = nlp(u'dog poodle beagle cat banana apple')"]},{"cell_type":"markdown","id":"3fa5c927-a59d-4447-b4fc-0e97da12253f","metadata":{"id":"3fa5c927-a59d-4447-b4fc-0e97da12253f"},"source":["As described in the spaCy chapter *[Word Vectors and Semantic Similarity](https://spacy.io/usage/vectors-similarity)*, the resulting elements of *Doc*, *Span*, and *Token* provide a method *similarity()*, which returns the similarities between words: "]},{"cell_type":"code","execution_count":6,"id":"5a2a76b7-d61f-4a67-9cf5-23fa47dfffa0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5a2a76b7-d61f-4a67-9cf5-23fa47dfffa0","executionInfo":{"status":"ok","timestamp":1666261053486,"user_tz":-120,"elapsed":4,"user":{"displayName":"Nils Holmberg","userId":"03719824180037236130"}},"outputId":"cc65b8a8-dd43-49fb-c9f8-1c4d972da5a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["dog dog 1.0\n","dog poodle 0.6339900493621826\n","dog beagle 0.5964534282684326\n","dog cat 0.8220816850662231\n","dog banana 0.2090904712677002\n","dog apple 0.22881005704402924\n","poodle dog 0.6339900493621826\n","poodle poodle 1.0\n","poodle beagle 0.6217650771141052\n","poodle cat 0.6388016939163208\n","poodle banana 0.2899792790412903\n","poodle apple 0.2370169311761856\n","beagle dog 0.5964534282684326\n","beagle poodle 0.6217650771141052\n","beagle beagle 1.0\n","beagle cat 0.5943629145622253\n","beagle banana 0.10636148601770401\n","beagle apple 0.120062917470932\n","cat dog 0.8220816850662231\n","cat poodle 0.6388016939163208\n","cat beagle 0.5943629145622253\n","cat cat 1.0\n","cat banana 0.2235882580280304\n","cat apple 0.2036806046962738\n","banana dog 0.2090904712677002\n","banana poodle 0.2899792790412903\n","banana beagle 0.10636148601770401\n","banana cat 0.2235882580280304\n","banana banana 1.0\n","banana apple 0.6646699905395508\n","apple dog 0.22881005704402924\n","apple poodle 0.2370169311761856\n","apple beagle 0.120062917470932\n","apple cat 0.2036806046962738\n","apple banana 0.6646699905395508\n","apple apple 1.0\n"]}],"source":["for token1 in tokens:\n","    for token2 in tokens:\n","        print(token1, token2, token1.similarity(token2))"]},{"cell_type":"markdown","id":"2343c049-408b-45ef-b53d-9f6ed0807135","metadata":{"id":"2343c049-408b-45ef-b53d-9f6ed0807135"},"source":["We can access the *vectors* of these objects using the *vector* attribute:"]},{"cell_type":"code","execution_count":12,"id":"a8b4572c-aa90-4ad0-9272-e37347e33c15","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a8b4572c-aa90-4ad0-9272-e37347e33c15","executionInfo":{"status":"ok","timestamp":1666261199004,"user_tz":-120,"elapsed":520,"user":{"displayName":"Nils Holmberg","userId":"03719824180037236130"}},"outputId":"a7d8496e-4804-4c2c-ead7-83aac3729b75"},"outputs":[{"output_type":"stream","name":"stdout","text":["dog True 75.254234 False\n","cat True 63.188496 False\n","banana True 31.620354 False\n","grungle False 0.0 True\n"]}],"source":["tokens = nlp(u'dog cat banana grungle')\n","\n","for token in tokens:\n","    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"]},{"cell_type":"markdown","id":"d3090df8-fac4-4617-9a99-5d002c7b3150","metadata":{"id":"d3090df8-fac4-4617-9a99-5d002c7b3150"},"source":["The attribute *has_vector* returns a boolean depending on whether the token has a vector in the model or not. The token *grungle* has no vector. It is also out-of-vocabulary (OOV), as the fourth column shows. Thus, it also has a norm of $0$, that is, it has a length of $0$."]},{"cell_type":"markdown","id":"38035d7d-0daf-490a-980c-73e895786e6e","metadata":{"id":"38035d7d-0daf-490a-980c-73e895786e6e"},"source":["Here the token vector has a length of $300$. We can print out the vector for a token:"]},{"cell_type":"code","execution_count":8,"id":"aaeef1f1-1158-466a-95d2-57007be6fac0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aaeef1f1-1158-466a-95d2-57007be6fac0","executionInfo":{"status":"ok","timestamp":1666261067937,"user_tz":-120,"elapsed":1245,"user":{"displayName":"Nils Holmberg","userId":"03719824180037236130"}},"outputId":"0d6f5c46-9e8e-4235-d95c-cabe88f8b1ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["dog 300 [ 1.2330e+00  4.2963e+00 -7.9738e+00 -1.0121e+01  1.8207e+00  1.4098e+00\n"," -4.5180e+00 -5.2261e+00 -2.9157e-01  9.5234e-01  6.9880e+00  5.0637e+00\n"," -5.5726e-03  3.3395e+00  6.4596e+00 -6.3742e+00  3.9045e-02 -3.9855e+00\n","  1.2085e+00 -1.3186e+00 -4.8886e+00  3.7066e+00 -2.8281e+00 -3.5447e+00\n","  7.6888e-01  1.5016e+00 -4.3632e+00  8.6480e+00 -5.9286e+00 -1.3055e+00\n","  8.3870e-01  9.0137e-01 -1.7843e+00 -1.0148e+00  2.7300e+00 -6.9039e+00\n","  8.0413e-01  7.4880e+00  6.1078e+00 -4.2130e+00 -1.5384e-01 -5.4995e+00\n","  1.0896e+01  3.9278e+00 -1.3601e-01  7.7732e-02  3.2218e+00 -5.8777e+00\n","  6.1359e-01 -2.4287e+00  6.2820e+00  1.3461e+01  4.3236e+00  2.4266e+00\n"," -2.6512e+00  1.1577e+00  5.0848e+00 -1.7058e+00  3.3824e+00  3.2850e+00\n","  1.0969e+00 -8.3711e+00 -1.5554e+00  2.0296e+00 -2.6796e+00 -6.9195e+00\n"," -2.3386e+00 -1.9916e+00 -3.0450e+00  2.4890e+00  7.3247e+00  1.3364e+00\n","  2.3828e-01  8.4388e-02  3.1480e+00 -1.1128e+00 -3.5598e+00 -1.2115e-01\n"," -2.0357e+00 -3.2731e+00 -7.7205e+00  4.0948e+00 -2.0732e+00  2.0833e+00\n"," -2.2803e+00 -4.9850e+00  9.7667e+00  6.1779e+00 -1.0352e+01 -2.2268e+00\n","  2.5765e+00 -5.7440e+00  5.5564e+00 -5.2735e+00  3.0004e+00 -4.2512e+00\n"," -1.5682e+00  2.2698e+00  1.0491e+00 -9.0486e+00  4.2936e+00  1.8709e+00\n","  5.1985e+00 -1.3153e+00  6.5224e+00  4.0113e-01 -1.2583e+01  3.6534e+00\n"," -2.0961e+00  1.0022e+00 -1.7873e+00 -4.2555e+00  7.7471e+00  1.0173e+00\n","  3.1626e+00  2.3558e+00  3.3589e-01 -4.4178e+00  5.0584e+00 -2.4118e+00\n"," -2.7445e+00  3.4170e+00 -1.1574e+01 -2.6568e+00 -3.6933e+00 -2.0398e+00\n","  5.0976e+00  6.5249e+00  3.3573e+00  9.5334e-01 -9.4430e-01 -9.4395e+00\n","  2.7867e+00 -1.7549e+00  1.7287e+00  3.4942e+00 -1.6883e+00 -3.5771e+00\n"," -1.9013e+00  2.2239e+00 -5.4335e+00 -6.5724e+00 -6.7228e-01 -1.9748e+00\n"," -3.1080e+00 -1.8570e+00  9.9496e-01  8.9135e-01 -4.4254e+00  3.3125e-01\n","  5.8815e+00  1.9384e+00  5.7294e-01 -2.8830e+00  3.8087e+00 -1.3095e+00\n","  5.9208e+00  3.3620e+00  3.3571e+00 -3.8807e-01  9.0022e-01 -5.5742e+00\n"," -4.2939e+00  1.4992e+00 -4.7080e+00 -2.9402e+00 -1.2259e+00  3.0980e-01\n","  1.8858e+00 -1.9867e+00 -2.3554e-01 -5.4535e-01 -2.1387e-01  2.4797e+00\n","  5.9710e+00 -7.1249e+00  1.6257e+00 -1.5241e+00  7.5974e-01  1.4312e+00\n","  2.3641e+00 -3.5566e+00  9.2066e-01  4.4934e-01 -1.3233e+00  3.1733e+00\n"," -4.7059e+00 -1.2090e+01 -3.9241e-01 -6.8457e-01 -3.6789e+00  6.6279e+00\n"," -2.9937e+00 -3.8361e+00  1.3868e+00 -4.9002e+00 -2.4299e+00  6.4312e+00\n","  2.5056e+00 -4.5080e+00 -5.1278e+00 -1.5585e+00 -3.0226e+00 -8.6811e-01\n"," -1.1538e+00 -1.0022e+00 -9.1651e-01 -4.7810e-01 -1.6084e+00 -2.7307e+00\n","  3.7080e+00  7.7423e-01 -1.1085e+00 -6.8755e-01 -8.2901e+00  3.2405e+00\n"," -1.6108e-01 -6.2837e-01 -5.5960e+00 -4.4865e+00  4.0115e-01 -3.7063e+00\n"," -2.1704e+00  4.0789e+00 -1.7973e+00  8.9538e+00  8.9421e-01 -4.8128e+00\n","  4.5367e+00 -3.2579e-01 -5.2344e+00 -3.9766e+00 -2.1979e+00  3.5699e+00\n","  1.4982e+00  6.0972e+00 -1.9704e+00  4.6522e+00 -3.7734e-01  3.9101e-02\n","  2.5361e+00 -1.8096e+00  8.7035e+00 -8.6372e+00 -3.5257e+00  3.1034e+00\n","  3.2635e+00  4.5437e+00 -5.7290e+00 -2.9141e-01 -2.0011e+00  8.5328e+00\n"," -4.5064e+00 -4.8276e+00 -1.1786e+01  3.5607e-01 -5.7115e+00  6.3122e+00\n"," -3.6650e+00  3.3597e-01  2.5017e+00 -3.5025e+00 -3.7891e+00 -3.1343e+00\n"," -1.4429e+00 -6.9119e+00 -2.6114e+00 -5.9757e-01  3.7847e-01  6.3187e+00\n","  2.8965e+00 -2.5397e+00  1.8022e+00  3.5486e+00  4.4721e+00 -4.8481e+00\n"," -3.6252e+00  4.0969e+00 -2.0081e+00 -2.0122e-01  2.5244e+00 -6.8817e-01\n","  6.7184e-01 -7.0466e+00  1.6641e+00 -2.2308e+00 -3.8960e+00  6.1320e+00\n"," -8.0335e+00 -1.7130e+00  2.5688e+00 -5.2547e+00  6.9845e+00  2.7835e-01\n"," -6.4554e+00 -2.1327e+00 -5.6515e+00  1.1174e+01 -8.0568e+00  5.7985e+00]\n"]}],"source":["n = 0\n","print(tokens[n].text, len(tokens[n].vector), tokens[n].vector)"]},{"cell_type":"markdown","id":"3dccbe5e-b7df-4c9c-a80f-802f4dd7fec3","metadata":{"id":"3dccbe5e-b7df-4c9c-a80f-802f4dd7fec3"},"source":["Here just another example of similarities for some famous words:"]},{"cell_type":"code","execution_count":9,"id":"b784b498-a531-4d86-980c-e91be0636707","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b784b498-a531-4d86-980c-e91be0636707","executionInfo":{"status":"ok","timestamp":1666261077512,"user_tz":-120,"elapsed":374,"user":{"displayName":"Nils Holmberg","userId":"03719824180037236130"}},"outputId":"d06806e1-e037-4121-b2e5-09bf427a7037"},"outputs":[{"output_type":"stream","name":"stdout","text":["queen queen 1.0\n","queen king 0.6108841896057129\n","queen chef 0.13113069534301758\n","king queen 0.6108841896057129\n","king king 1.0\n","king chef 0.04403642565011978\n","chef queen 0.13113069534301758\n","chef king 0.04403642565011978\n","chef chef 1.0\n"]}],"source":["tokens = nlp(u'queen king chef')\n","\n","for token1 in tokens:\n","    for token2 in tokens:\n","        print(token1, token2, token1.similarity(token2))"]},{"cell_type":"markdown","id":"b9dbee8a-9bb5-4e1b-8247-b24d07c813d0","metadata":{"id":"b9dbee8a-9bb5-4e1b-8247-b24d07c813d0"},"source":["### Similarities in Context"]},{"cell_type":"markdown","id":"fa212336-5585-4d3a-8298-23415bdbe95e","metadata":{"id":"fa212336-5585-4d3a-8298-23415bdbe95e"},"source":["In spaCy parsing, tagging and NER models make use of vector representations of contexts that represent the *meaning of words*. A text *meaning representation* is represented as an array of floats, i.e. a tensor, computed during the NLP pipeline processing. With this approach words that have not been seen before can be typed or classified. SpaCy uses a 4-layer convolutional network for the computation of these tensors. In this approach these tensors model a context of four words left and right of any given word."]},{"cell_type":"markdown","id":"0e3a1abc-6f11-45b3-be70-f4eca708cce4","metadata":{"id":"0e3a1abc-6f11-45b3-be70-f4eca708cce4"},"source":["Let us use the example from the spaCy documentation and check the word *labrador*:"]},{"cell_type":"code","execution_count":null,"id":"e594d98f-84c2-4a8f-b4a7-c45b321aa374","metadata":{"id":"e594d98f-84c2-4a8f-b4a7-c45b321aa374","outputId":"2d20df70-01a4-4667-c60a-9f3707152bb1"},"outputs":[{"name":"stdout","output_type":"stream","text":["labrador True 6.850418 False\n"]}],"source":["tokens = nlp(u'labrador')\n","\n","for token in tokens:\n","    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"]},{"cell_type":"markdown","id":"7e336b0f-6fdc-461b-a5cf-54f6f5d99022","metadata":{"id":"7e336b0f-6fdc-461b-a5cf-54f6f5d99022"},"source":["We can now test for the context:"]},{"cell_type":"code","execution_count":null,"id":"843bdae2-4008-4132-9f44-5945ea6363bf","metadata":{"id":"843bdae2-4008-4132-9f44-5945ea6363bf","outputId":"4c38ca4a-70d9-4391-c4f1-b67178335036"},"outputs":[{"name":"stdout","output_type":"stream","text":["1: 0.6907751984080799\n","2: 0.5961927660740638\n","3: 0.5374588437026319\n"]}],"source":["doc1 = nlp(u\"The labrador barked.\")\n","doc2 = nlp(u\"The labrador swam.\")\n","doc3 = nlp(u\"The people on Labrador are Canadians.\")\n","\n","dog = nlp(u\"dog\")\n","\n","count = 0\n","for doc in [doc1, doc2, doc3]:\n","    lab = doc\n","    count += 1\n","    print(str(count) + \":\", lab.similarity(dog))"]},{"cell_type":"markdown","id":"26f3e165-27f9-4551-9105-3cb8929d88d2","metadata":{"id":"26f3e165-27f9-4551-9105-3cb8929d88d2"},"source":["Using this strategy we can compute document or text similarities as well:"]},{"cell_type":"code","execution_count":null,"id":"9c90e1fa-c4d3-4d5f-947e-a8b43daca2da","metadata":{"id":"9c90e1fa-c4d3-4d5f-947e-a8b43daca2da","outputId":"0846f32e-cccd-48bf-f819-67b127a0196a"},"outputs":[{"name":"stdout","output_type":"stream","text":["0 1 0.7554966079333336\n","0 2 0.6921463288355282\n","1 0 0.7554966079333336\n","1 2 0.5668025741640493\n","2 0 0.6921463288355282\n","2 1 0.5668025741640493\n"]}],"source":["docs = ( nlp(u\"Paris is the largest city in France.\"),\n","        nlp(u\"Vilnius is the capital of Lithuania.\"),\n","        nlp(u\"An emu is a large bird.\") )\n","\n","for x in range(len(docs)):\n","    zset = set(range(len(docs)))\n","    zset.remove(x)\n","    for y in zset:\n","        print(x, y, docs[x].similarity(docs[y]))"]},{"cell_type":"markdown","id":"75ffc7ff-2799-4ffd-b91c-15a61b1fee27","metadata":{"id":"75ffc7ff-2799-4ffd-b91c-15a61b1fee27"},"source":["We can vary the word order in sentences and compare them:"]},{"cell_type":"code","execution_count":null,"id":"0a6f0d60-8ec6-432b-babe-ea3d366299ad","metadata":{"id":"0a6f0d60-8ec6-432b-babe-ea3d366299ad","outputId":"2fd3278c-7eeb-4c34-e41f-d2f23dc88fbf"},"outputs":[{"name":"stdout","output_type":"stream","text":["\"dog bites man\" \"dog bites man\" 1.0\n","\"dog bites man\" \"man bites dog\" 0.9999999711588186\n","\"dog bites man\" \"man dog bites\" 1.000000047362914\n","\"dog bites man\" \"cat eats mouse\" 0.7096954239846529\n","\"man bites dog\" \"dog bites man\" 0.9999999711588186\n","\"man bites dog\" \"man bites dog\" 1.0\n","\"man bites dog\" \"man dog bites\" 1.0000000462548106\n","\"man bites dog\" \"cat eats mouse\" 0.709695423198237\n","\"man dog bites\" \"dog bites man\" 1.000000047362914\n","\"man dog bites\" \"man bites dog\" 1.0000000462548106\n","\"man dog bites\" \"man dog bites\" 1.0\n","\"man dog bites\" \"cat eats mouse\" 0.7096954242750528\n","\"cat eats mouse\" \"dog bites man\" 0.7096954239846529\n","\"cat eats mouse\" \"man bites dog\" 0.709695423198237\n","\"cat eats mouse\" \"man dog bites\" 0.7096954242750528\n","\"cat eats mouse\" \"cat eats mouse\" 1.0\n"]}],"source":["docs = [nlp(u\"dog bites man\"), nlp(u\"man bites dog\"),\n","        nlp(u\"man dog bites\"), nlp(u\"cat eats mouse\")]\n","\n","for doc in docs:\n","    for other_doc in docs:\n","        print('\"' + doc.text + '\"', '\"' + other_doc.text + '\"', doc.similarity(other_doc))"]},{"cell_type":"markdown","id":"d2ec2d22-373f-4ecd-9b10-cf2ebd678824","metadata":{"id":"d2ec2d22-373f-4ecd-9b10-cf2ebd678824"},"source":["### Custom Models"]},{"cell_type":"code","execution_count":null,"id":"8d6c3eb6-b241-4392-a15e-affdb4c1f327","metadata":{"id":"8d6c3eb6-b241-4392-a15e-affdb4c1f327"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"colab":{"provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}