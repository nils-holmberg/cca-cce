{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a015b51b-d728-465e-aed9-493146b9935e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42854afb-74d8-401d-a35a-6b57ebcdb710",
   "metadata": {},
   "source": [
    "### Word vectors and similarity \n",
    "\n",
    "To learn more about word vectors, how to **customize them** and how to load\n",
    "**your own vectors** into spaCy, see the usage guide on\n",
    "[using word vectors and semantic similarities](/usage/linguistic-features#vectors-similarity).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "935f88d0-5246-41d2-a25a-a77d10482cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c0cb4e-8ae8-4c20-98a1-39246f4f59a8",
   "metadata": {},
   "source": [
    "## Word vectors and similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168161dc-94b9-493e-92e9-b02e87c4d3f4",
   "metadata": {},
   "source": [
    "To use vectors in spaCy, you might consider installing the larger models for the particular language. The common module and language packages only come with the small models. The larger models can be installed as described on the [spaCy vectors page](https://spacy.io/usage/vectors-similarity):\n",
    "\n",
    "    python -m spacy download en_core_web_lg\n",
    "\n",
    "The large model *en_core_web_lg* contains more than 1 million unique vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3534fd3d-3595-460c-87e3-4a01ab36fd0a",
   "metadata": {},
   "source": [
    "Let us restart all necessary modules again, in particular spaCy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80abb48d-c176-4f98-89ab-27c2aac01b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f4f516-9a62-41ee-87bc-e97afd5c98d1",
   "metadata": {},
   "source": [
    "We can now import the English NLP pipeline to process some word list. Since the small models in spacy only include context-sensitive tensors, we should use the dowloaded large model for better word vectors. We load the large model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc35f254-07f0-427f-af53-988eff474f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "#nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab34cf8-42bc-43ba-9fed-47f4af3d7fe3",
   "metadata": {},
   "source": [
    "We can process a list of words by the pipeline using the *nlp* object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db26d415-b60b-48ef-a4c5-f719c9a705f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nlp(u'dog poodle beagle cat banana apple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa5c927-a59d-4447-b4fc-0e97da12253f",
   "metadata": {},
   "source": [
    "As described in the spaCy chapter *[Word Vectors and Semantic Similarity](https://spacy.io/usage/vectors-similarity)*, the resulting elements of *Doc*, *Span*, and *Token* provide a method *similarity()*, which returns the similarities between words: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a2a76b7-d61f-4a67-9cf5-23fa47dfffa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog dog 1.0\n",
      "dog poodle 0.67507446\n",
      "dog beagle 0.66592145\n",
      "dog cat 0.80168545\n",
      "dog banana 0.24327648\n",
      "dog apple 0.26339024\n",
      "poodle dog 0.67507446\n",
      "poodle poodle 1.0\n",
      "poodle beagle 0.71166867\n",
      "poodle cat 0.573045\n",
      "poodle banana 0.22574891\n",
      "poodle apple 0.19250016\n",
      "beagle dog 0.66592145\n",
      "beagle poodle 0.71166867\n",
      "beagle beagle 1.0\n",
      "beagle cat 0.55627644\n",
      "beagle banana 0.17828682\n",
      "beagle apple 0.21266587\n",
      "cat dog 0.80168545\n",
      "cat poodle 0.573045\n",
      "cat beagle 0.55627644\n",
      "cat cat 1.0\n",
      "cat banana 0.2815437\n",
      "cat apple 0.28213844\n",
      "banana dog 0.24327648\n",
      "banana poodle 0.22574891\n",
      "banana beagle 0.17828682\n",
      "banana cat 0.2815437\n",
      "banana banana 1.0\n",
      "banana apple 0.5831844\n",
      "apple dog 0.26339024\n",
      "apple poodle 0.19250016\n",
      "apple beagle 0.21266587\n",
      "apple cat 0.28213844\n",
      "apple banana 0.5831844\n",
      "apple apple 1.0\n"
     ]
    }
   ],
   "source": [
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1, token2, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2343c049-408b-45ef-b53d-9f6ed0807135",
   "metadata": {},
   "source": [
    "We can access the *vectors* of these objects using the *vector* attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8b4572c-aa90-4ad0-9272-e37347e33c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog True 7.0336733 False\n",
      "cat True 6.6808186 False\n",
      "banana True 6.700014 False\n",
      "grungle False 0.0 True\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp(u'dog cat banana grungle')\n",
    "\n",
    "for token in tokens:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3090df8-fac4-4617-9a99-5d002c7b3150",
   "metadata": {},
   "source": [
    "The attribute *has_vector* returns a boolean depending on whether the token has a vector in the model or not. The token *grungle* has no vector. It is also out-of-vocabulary (OOV), as the fourth column shows. Thus, it also has a norm of $0$, that is, it has a length of $0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38035d7d-0daf-490a-980c-73e895786e6e",
   "metadata": {},
   "source": [
    "Here the token vector has a length of $300$. We can print out the vector for a token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaeef1f1-1158-466a-95d2-57007be6fac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog 300 [-4.0176e-01  3.7057e-01  2.1281e-02 -3.4125e-01  4.9538e-02  2.9440e-01\n",
      " -1.7376e-01 -2.7982e-01  6.7622e-02  2.1693e+00 -6.2691e-01  2.9106e-01\n",
      " -6.7270e-01  2.3319e-01 -3.4264e-01  1.8311e-01  5.0226e-01  1.0689e+00\n",
      "  1.4698e-01 -4.5230e-01 -4.1827e-01 -1.5967e-01  2.6748e-01 -4.8867e-01\n",
      "  3.6462e-01 -4.3403e-02 -2.4474e-01 -4.1752e-01  8.9088e-02 -2.5552e-01\n",
      " -5.5695e-01  1.2243e-01 -8.3526e-02  5.5095e-01  3.6410e-01  1.5361e-01\n",
      "  5.5738e-01 -9.0702e-01 -4.9098e-02  3.8580e-01  3.8000e-01  1.4425e-01\n",
      " -2.7221e-01 -3.7016e-01 -1.2904e-01 -1.5085e-01 -3.8076e-01  4.9583e-02\n",
      "  1.2755e-01 -8.2788e-02  1.4339e-01  3.2537e-01  2.7226e-01  4.3632e-01\n",
      " -3.1769e-01  7.9405e-01  2.6529e-01  1.0135e-01 -3.3279e-01  4.3117e-01\n",
      "  1.6687e-01  1.0729e-01  8.9418e-02  2.8635e-01  4.0117e-01 -3.9222e-01\n",
      "  4.5217e-01  1.3521e-01 -2.8878e-01 -2.2819e-02 -3.4975e-01 -2.2996e-01\n",
      "  2.0224e-01 -2.1177e-01  2.7184e-01  9.1703e-02 -2.0610e-01 -6.5758e-01\n",
      "  1.8949e-01 -2.6756e-01  9.2639e-02  4.3316e-01 -4.8868e-01 -3.8309e-01\n",
      " -2.1910e-01 -4.4183e-01  9.8044e-01  6.7423e-01  8.4003e-01 -1.8169e-01\n",
      "  1.7385e-01  4.1848e-01  1.6098e-01 -1.0490e-01 -4.1965e-01 -3.5660e-01\n",
      " -1.6837e-01 -6.3458e-01  3.8422e-01 -3.5043e-01  1.7486e-01  5.3528e-01\n",
      "  2.0143e-01  3.7877e-02  4.7105e-01 -4.4344e-01  1.6840e-01 -1.6685e-01\n",
      " -2.4022e-01 -1.0077e-01  3.0334e-01  4.2730e-01  3.3803e-01 -4.3481e-01\n",
      "  1.1343e-01  6.1958e-02  6.1808e-02 -1.4007e-01  8.2018e-02 -3.9130e-02\n",
      "  5.1442e-02  2.8725e-01  5.8025e-01 -5.7641e-01 -3.4652e-01  1.0132e-01\n",
      "  1.4463e-01  1.1569e-02 -3.3701e-01 -1.7586e-01 -3.5724e-01 -2.1423e-01\n",
      "  1.1429e-02  4.7645e-01 -3.7463e-02 -2.9488e-01 -1.7465e-01  3.0255e-01\n",
      "  6.0317e-01 -6.6790e-02 -2.7050e+00 -7.0308e-01  4.0548e-01  6.2874e-01\n",
      "  6.3080e-01 -5.4513e-01 -9.6191e-03  2.6533e-01  2.3391e-01 -5.1886e-02\n",
      " -6.5759e-03  1.8573e-02 -4.5693e-01 -7.0351e-02 -3.0621e-01 -1.4018e-02\n",
      " -2.0408e-01  3.7100e-01 -3.2354e-01 -8.4646e-01  2.7092e-01 -1.1961e-01\n",
      " -9.5576e-02 -6.0464e-01  4.2409e-02  2.4656e-01  3.8445e-02 -2.5467e-02\n",
      " -9.2908e-02 -2.1356e-01  3.6120e-01  1.9113e-02  6.2741e-02 -1.3083e-01\n",
      " -1.5146e-03  5.8238e-01 -1.8956e-01  7.8105e-01  1.0477e-02  1.0928e+00\n",
      "  1.0140e-01 -3.6248e-01 -1.1962e-01 -3.4462e-01 -5.5704e-01  2.5797e-01\n",
      "  3.3356e-01  3.3194e-01 -3.1298e-01 -7.5547e-01 -7.5290e-01 -9.3072e-02\n",
      " -1.1173e-01 -5.7251e-01  1.6639e-01  6.3579e-01  2.4006e-01 -2.9211e-01\n",
      "  9.0182e-01  1.2425e-01 -5.7751e-01  4.7986e-02 -4.2748e-01  2.4446e-01\n",
      "  4.7232e-02  3.5694e-01  4.4241e-01 -2.3055e-01  6.6037e-01 -7.3983e-03\n",
      " -3.7857e-01  2.2759e-01 -3.7138e-01  3.1055e-01 -7.2105e-02 -2.4490e-01\n",
      " -3.9761e-02  5.3650e-01 -4.1478e-01  1.6563e-01  3.3707e-01  1.0920e-01\n",
      "  3.7219e-01 -5.5727e-01 -7.8060e-01  1.4251e-01 -3.5828e-01  4.1638e-01\n",
      "  2.1446e-01  1.8410e-01 -4.7704e-01 -2.2005e-02 -2.3634e-01 -2.2840e-01\n",
      "  3.4722e-01  2.3667e-01  7.4249e-02 -8.8416e-02  2.8618e-01 -4.6942e-01\n",
      " -4.3914e-01 -2.6474e-01 -3.0690e-01 -1.5260e-01 -8.4870e-02  2.8410e-01\n",
      " -1.8481e-01 -2.2122e-01 -1.1169e-01 -2.5241e-02  4.5968e-02  3.5343e-02\n",
      "  2.2467e-01  5.1556e-01 -6.5137e-04  9.9559e-02 -1.4215e-01  2.0136e-01\n",
      "  2.8334e-01 -2.8772e-01  3.7766e-02 -3.7608e-01 -1.1681e-01 -6.7020e-01\n",
      " -4.6265e-02  3.8784e-01 -3.2295e-02 -5.4291e-02 -4.5384e-01  1.9552e-01\n",
      " -2.9470e-01  8.5009e-01  1.0345e-01  9.7010e-02  1.1339e-01  3.9502e-01\n",
      "  5.9043e-02  2.1978e-01  1.8845e-01 -1.5891e-01 -1.0301e-01  3.3164e-01\n",
      "  6.1477e-02 -2.9848e-01  4.4510e-01  4.7329e-01  2.6312e-01 -1.8495e-01\n",
      "  1.4652e-01 -3.1510e-02  2.2908e-02 -2.5929e-01 -3.0862e-01  1.7545e-03\n",
      " -1.8962e-01  5.4789e-01  3.1194e-01  2.4693e-01  2.9929e-01 -7.4861e-02]\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "print(tokens[n].text, len(tokens[n].vector), tokens[n].vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dccbe5e-b7df-4c9c-a80f-802f4dd7fec3",
   "metadata": {},
   "source": [
    "Here just another example of similarities for some famous words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b784b498-a531-4d86-980c-e91be0636707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queen queen 1.0\n",
      "queen king 0.72526103\n",
      "queen chef 0.24236034\n",
      "king queen 0.72526103\n",
      "king king 1.0\n",
      "king chef 0.25258547\n",
      "chef queen 0.24236034\n",
      "chef king 0.25258547\n",
      "chef chef 1.0\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp(u'queen king chef')\n",
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1, token2, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dbee8a-9bb5-4e1b-8247-b24d07c813d0",
   "metadata": {},
   "source": [
    "### Similarities in Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa212336-5585-4d3a-8298-23415bdbe95e",
   "metadata": {},
   "source": [
    "In spaCy parsing, tagging and NER models make use of vector representations of contexts that represent the *meaning of words*. A text *meaning representation* is represented as an array of floats, i.e. a tensor, computed during the NLP pipeline processing. With this approach words that have not been seen before can be typed or classified. SpaCy uses a 4-layer convolutional network for the computation of these tensors. In this approach these tensors model a context of four words left and right of any given word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3a1abc-6f11-45b3-be70-f4eca708cce4",
   "metadata": {},
   "source": [
    "Let us use the example from the spaCy documentation and check the word *labrador*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e594d98f-84c2-4a8f-b4a7-c45b321aa374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labrador True 6.850418 False\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp(u'labrador')\n",
    "\n",
    "for token in tokens:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e336b0f-6fdc-461b-a5cf-54f6f5d99022",
   "metadata": {},
   "source": [
    "We can now test for the context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "843bdae2-4008-4132-9f44-5945ea6363bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 0.6907751984080799\n",
      "2: 0.5961927660740638\n",
      "3: 0.5374588437026319\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(u\"The labrador barked.\")\n",
    "doc2 = nlp(u\"The labrador swam.\")\n",
    "doc3 = nlp(u\"The people on Labrador are Canadians.\")\n",
    "\n",
    "dog = nlp(u\"dog\")\n",
    "\n",
    "count = 0\n",
    "for doc in [doc1, doc2, doc3]:\n",
    "    lab = doc\n",
    "    count += 1\n",
    "    print(str(count) + \":\", lab.similarity(dog))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f3e165-27f9-4551-9105-3cb8929d88d2",
   "metadata": {},
   "source": [
    "Using this strategy we can compute document or text similarities as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c90e1fa-c4d3-4d5f-947e-a8b43daca2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 0.7554966079333336\n",
      "0 2 0.6921463288355282\n",
      "1 0 0.7554966079333336\n",
      "1 2 0.5668025741640493\n",
      "2 0 0.6921463288355282\n",
      "2 1 0.5668025741640493\n"
     ]
    }
   ],
   "source": [
    "docs = ( nlp(u\"Paris is the largest city in France.\"),\n",
    "        nlp(u\"Vilnius is the capital of Lithuania.\"),\n",
    "        nlp(u\"An emu is a large bird.\") )\n",
    "\n",
    "for x in range(len(docs)):\n",
    "    zset = set(range(len(docs)))\n",
    "    zset.remove(x)\n",
    "    for y in zset:\n",
    "        print(x, y, docs[x].similarity(docs[y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ffc7ff-2799-4ffd-b91c-15a61b1fee27",
   "metadata": {},
   "source": [
    "We can vary the word order in sentences and compare them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a6f0d60-8ec6-432b-babe-ea3d366299ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"dog bites man\" \"dog bites man\" 1.0\n",
      "\"dog bites man\" \"man bites dog\" 0.9999999711588186\n",
      "\"dog bites man\" \"man dog bites\" 1.000000047362914\n",
      "\"dog bites man\" \"cat eats mouse\" 0.7096954239846529\n",
      "\"man bites dog\" \"dog bites man\" 0.9999999711588186\n",
      "\"man bites dog\" \"man bites dog\" 1.0\n",
      "\"man bites dog\" \"man dog bites\" 1.0000000462548106\n",
      "\"man bites dog\" \"cat eats mouse\" 0.709695423198237\n",
      "\"man dog bites\" \"dog bites man\" 1.000000047362914\n",
      "\"man dog bites\" \"man bites dog\" 1.0000000462548106\n",
      "\"man dog bites\" \"man dog bites\" 1.0\n",
      "\"man dog bites\" \"cat eats mouse\" 0.7096954242750528\n",
      "\"cat eats mouse\" \"dog bites man\" 0.7096954239846529\n",
      "\"cat eats mouse\" \"man bites dog\" 0.709695423198237\n",
      "\"cat eats mouse\" \"man dog bites\" 0.7096954242750528\n",
      "\"cat eats mouse\" \"cat eats mouse\" 1.0\n"
     ]
    }
   ],
   "source": [
    "docs = [nlp(u\"dog bites man\"), nlp(u\"man bites dog\"),\n",
    "        nlp(u\"man dog bites\"), nlp(u\"cat eats mouse\")]\n",
    "\n",
    "for doc in docs:\n",
    "    for other_doc in docs:\n",
    "        print('\"' + doc.text + '\"', '\"' + other_doc.text + '\"', doc.similarity(other_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ec2d22-373f-4ecd-9b10-cf2ebd678824",
   "metadata": {},
   "source": [
    "### Custom Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6c3eb6-b241-4392-a15e-affdb4c1f327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
